# CS2 Predictor

ML-based match outcome predictor for Counter-Strike 2. Collects historical match data from the Liquipedia API, engineers features from team performance history, and trains classification models to predict match winners with calibrated probabilities.

## Overview

The system is an end-to-end pipeline with four stages:

1. **Data collection** - Fetches tournament and match data from the Liquipedia API (v3), covering all CS2 matches since the game's release (October 2023).
2. **Feature engineering** - Processes matches chronologically to compute 26 features per matchup: Elo ratings, rolling win rates, recent form, win/loss streaks, head-to-head records, tier-specific performance, and tournament context.
3. **Model training** - Trains four classifiers (logistic regression, random forest, XGBoost, gradient boosting) using a time-based train/test split and selects the best by log loss.
4. **Prediction** - Constructs a live feature vector from current team stats and outputs calibrated win probabilities.

## Project Structure

```
cs2-predictor/
├── src/
│   ├── config.py                           # API keys, rate limits, timeouts
│   ├── predict.py                          # Prediction CLI
│   ├── fetch/
│   │   ├── tournaments.py                  # Liquipedia tournament API client
│   │   └── matches.py                      # Liquipedia match API client
│   ├── parse/
│   │   ├── tournaments.py                  # Tournament response normalization
│   │   └── matches.py                      # Match response normalization
│   ├── pipelines/
│   │   ├── build_tournaments.py            # Step 1: fetch & save tournaments
│   │   ├── build_matches.py                # Step 2: fetch & save matches
│   │   └── deduplicate_matches.py          # Step 3: remove duplicate matches
│   ├── features/
│   │   ├── elo.py                          # Elo rating system (adaptive K-factor)
│   │   ├── team_stats.py                   # Rolling stats tracker (win rates, streaks, H2H)
│   │   └── build_features.py              # Step 4: build feature matrix
│   ├── model/
│   │   ├── train.py                        # Step 5: train & evaluate models
│   │   └── evaluate.py                     # Metrics (accuracy, log loss, AUC, Brier)
│   └── utils/
│       ├── logger.py                       # Logging configuration
│       ├── rate_limiter_v2.py              # API rate limiter (distributed strategy)
│       ├── retry_handler.py                # Retry logic with exponential backoff
│       ├── validators.py                   # Date and data validation
│       └── exceptions.py                   # Custom exceptions
├── data/                                   # gitignored - generated by pipeline
│   ├── processed/
│   │   ├── cs2_tournaments.csv             # Tournament data
│   │   ├── cs2_matches.csv                 # Raw match data
│   │   ├── cs2_matches_deduplicated.csv    # Deduplicated match data
│   │   └── feature_matrix.csv              # Training features
│   └── models/
│       ├── best_model.joblib               # Best model by log loss
│       ├── model_logistic_regression.joblib
│       ├── model_random_forest.joblib
│       ├── model_xgboost.joblib
│       ├── model_gradient_boosting.joblib
│       ├── scaler.joblib                   # StandardScaler for logistic regression
│       ├── elo_ratings.json                # Final Elo ratings for all teams
│       ├── team_stats.json                 # Full team stats history
│       ├── training_metadata.json          # Train/test split info, metrics
│       ├── feature_importances.json        # Feature importances per model
│       └── calibration_curve.png           # Calibration plot for best model
└── .gitignore
```

## Setup

### Prerequisites

- Python 3.12+
- A [Liquipedia API key](https://liquipedia.net/api-terms-of-use)

### Installation

```bash
python -m venv .venv
source .venv/bin/activate
pip install pandas numpy scikit-learn xgboost joblib matplotlib requests python-dotenv
```

### Configuration

Create a `.env` file in the project root:

```
LIQUIPEDIA_API_KEY=your_key_here
```

The API is rate-limited to 60 requests per hour (configurable in `src/config.py`). The pipeline handles this automatically with a distributed rate limiter and exponential backoff retries.

## Usage

All commands are run from the project root with the virtual environment activated.

### Full Pipeline

```bash
# 1. Fetch tournaments from Liquipedia
python -m src.pipelines.build_tournaments

# 2. Fetch matches for each tournament
python -m src.pipelines.build_matches

# 3. Deduplicate match data
python -m src.pipelines.deduplicate_matches

# 4. Build feature matrix
python -m src.features.build_features

# 5. Train models
python -m src.model.train

# 6. Predict a match
python -m src.predict --team1 "Natus Vincere" --team2 "FaZe Clan"
```

### Step Details

**Fetch tournaments** - Queries the Liquipedia tournament API for all CS2 events. Saves to `data/processed/cs2_tournaments.csv`.

```bash
python -m src.pipelines.build_tournaments
    --start-date YYYY-MM-DD   # default: 2023-10-15 (CS2 release)
    --end-date YYYY-MM-DD     # default: today
```

**Fetch matches** - Iterates through each tournament and fetches all match results. Saves raw data with checkpoints after each tournament, so interrupted runs can resume. Outputs `data/processed/cs2_matches.csv`.

```bash
python -m src.pipelines.build_matches
    --incremental              # only fetch recent tournaments
    --from-date YYYY-MM-DD     # override start date for incremental
```

**Deduplicate matches** - Creates a clean copy of match data with duplicate match IDs removed. The raw file is preserved. Outputs `data/processed/cs2_matches_deduplicated.csv`.

```bash
python -m src.pipelines.deduplicate_matches
    --input PATH               # default: data/processed/cs2_matches.csv
    --output PATH              # default: data/processed/cs2_matches_deduplicated.csv
    --strategy first|latest    # keep first occurrence or most recent (default: first)
```

**Build features** - Processes matches chronologically, computing features using only data available before each match (no leakage). Teams with fewer than 5 prior matches are excluded. Saves the feature matrix and serialized Elo ratings and team stats.

```bash
python -m src.features.build_features
```

**Train models** - Trains all four models, evaluates on the test set, selects the best by log loss, and saves all artifacts to `data/models/`.

```bash
python -m src.model.train
```

## Making Predictions

```bash
# Basic prediction
python -m src.predict --team1 "Natus Vincere" --team2 "FaZe Clan"

# With tournament context
python -m src.predict --team1 "G2 Esports" --team2 "Team Vitality" \
    --tier 1 --prizepool 1250000 --type Offline

# JSON output
python -m src.predict --team1 "MOUZ" --team2 "Team Spirit" --json

# Use a specific model
python -m src.predict --team1 "Cloud9" --team2 "Heroic" --model xgboost

# List top teams by Elo rating
python -m src.predict --list-teams
```

### Prediction Options

| Flag | Description | Default |
|------|-------------|---------|
| `--team1` | First team name (exact Liquipedia name) | required |
| `--team2` | Second team name (exact Liquipedia name) | required |
| `--tier` | Tournament tier 1-4 | 2 |
| `--prizepool` | Prize pool in USD | 50000 |
| `--type` | `Online`, `Offline`, or `Online/Offline` | Offline |
| `--model` | `best`, `logistic_regression`, `random_forest`, `xgboost`, `gradient_boosting` | best |
| `--json` | Output as JSON | off |
| `--list-teams` | Show top teams ranked by Elo | off |

Team names must match Liquipedia exactly (e.g., "Natus Vincere" not "NaVi", "FaZe Clan" not "FaZe"). Use `--list-teams` to see available team names.

## How It Works

### Data Collection

Tournament and match data is fetched from the [Liquipedia API v3](https://liquipedia.net/counterstrike/api). The pipeline paginates through results with built-in rate limiting (60 req/hour), exponential backoff retries, and checkpoint-based resumption for long-running fetches.

### Feature Engineering

Each match is processed chronologically. Features are extracted using only data available *before* that match to prevent data leakage. The 26 features fall into six categories:

| Category | Features | Description |
|----------|----------|-------------|
| **Elo ratings** | `team1_elo`, `team2_elo`, `elo_diff` | Adaptive Elo system (K=48 for <30 matches, K=32 otherwise, default 1500) |
| **Win rates** | `team1_wr_all`, `team2_wr_all`, `wr_diff_all`, `team1_wr_20`, `team2_wr_20`, `team1_wr_50`, `team2_wr_50` | Overall and rolling window (last 20, 50 matches) win rates |
| **Form** | `team1_form`, `team2_form`, `form_diff` | Win rate over last 10 matches |
| **Streaks** | `team1_streak`, `team2_streak`, `streak_diff` | Current win/loss streak (positive = wins, negative = losses) |
| **Head-to-head** | `h2h_wr` | Team 1's historical win rate against team 2 |
| **Tier-specific** | `team1_tier_wr`, `team2_tier_wr` | Win rate at the specific tournament tier |
| **Activity** | `team1_days_since_last`, `team2_days_since_last` | Days since each team's last match |
| **Tournament context** | `tier`, `log_prizepool`, `is_online`, `is_offline`, `is_hybrid` | Tournament metadata (prizepool is log-transformed) |

### Model Training

Four classifiers are trained on an 80/20 time-based split (earlier matches for training, later for testing):

- **Logistic Regression** - StandardScaler preprocessing, max 1000 iterations
- **Random Forest** - 200 trees, max depth 10, min 20 samples per leaf
- **XGBoost** - 200 estimators, max depth 6, learning rate 0.1
- **Gradient Boosting** - 200 estimators, max depth 5, learning rate 0.1

Models are evaluated on accuracy, log loss, ROC AUC, and Brier score. The best model is selected by log loss (measures probability calibration quality). A calibration curve is generated for visual inspection.

### Prediction

At prediction time, the system:

1. Loads the saved Elo ratings, team stats, model, and scaler
2. Constructs a feature vector from the current state of both teams
3. Runs the feature vector through the model to get class probabilities
4. Outputs win probabilities, predicted winner, confidence, and supporting context (Elo, match counts, H2H record)

Teams with no match history get default ratings (Elo 1500, 50% win rates). The system warns when a team has limited data.

## Data Pipeline

```
Liquipedia API
     │
     ▼
┌─────────────────────┐
│  build_tournaments   │ ──► data/processed/cs2_tournaments.csv
└─────────────────────┘
     │
     ▼
┌─────────────────────┐
│   build_matches      │ ──► data/processed/cs2_matches.csv
└─────────────────────┘
     │
     ▼
┌─────────────────────┐
│ deduplicate_matches  │ ──► data/processed/cs2_matches_deduplicated.csv
└─────────────────────┘
     │
     ▼
┌─────────────────────┐
│  build_features      │ ──► data/processed/feature_matrix.csv
└─────────────────────┘     + data/models/elo_ratings.json
     │                      + data/models/team_stats.json
     ▼
┌─────────────────────┐
│   train models       │ ──► data/models/*.joblib
└─────────────────────┘     + data/models/training_metadata.json
     │                      + data/models/feature_importances.json
     ▼                      + data/models/calibration_curve.png
┌─────────────────────┐
│     predict          │ ──► win probabilities + context
└─────────────────────┘
```
